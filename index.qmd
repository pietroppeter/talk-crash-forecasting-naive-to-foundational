---
title: A Crash course in Time Series Forecasting from Naive to Foundational
# author used as subtitle
author: Pietro Peterlongo, Data Scientist @ AgileLab
format:
  revealjs:
    logo: agilelab.png
    footer: "PyCon Lithuania, Vilnius, 250424"
    execute:
      echo: true
---
## Agenda

todo

## 👋 Hi, I am Pietro  👨‍👩‍👧

- Data Scientist @ [agilelab.it](agilelab.it) ⚪️🔵
  - 📘[handbook](), 🤙[holacracy]() (self-management)
- (previously) 8+ years at Software Vendor in Supply Chain
- 🐍🇮🇹 Python/PyData Milano [milano.python.it]()
- 🐙 [github.com/pietroppeter](github.com/pietroppeter) (👈 more socials 🔗)

🎪 Come to PyCon Italy (Bologna, May 29-31)! 🍝

## why forecasting?

domains

- 📈 sales/demand
- 🔋 energy consumption
- 💹 financial assets
- 🌤️ weather
- ...

where is the (business) value? 💰

take better decisions! 💡

## 🏹 taking time seriously

time is the most important dimension

- time frequency (months, weeks, days, hours, ...)
- time horizon (how many weeks in the future)?
- lag n forecast: the forecast for the n-th time bucket in the future

other dimensions (e.g. product, market, ...) usually lead
to forecasting _multiple_ time series (or _multivariate_ ones)

## nixtla

![](images/nixtla.png)

## methodology

1. think about your why
2. gather data (process, explore)
3. baseline
4. measure
5. improve
6. restart from step 4 or less

## example 1: AirPassengers

todo

## baseline (options)

- Historical average
- Naive (aka persistence in weather forecasting)
- Moving Average
- Seasonal Naive
- ..., existing forecast (benchmark)

## baseline (code)

todo

## measure (metrics)

todo

## cross validation

![](images/crossvalidation.gif)

## measure (code)

todo

## statforecast

todo

## M5 Forecasting competition

```python
from datasetsforecast.m5 import M5
Y_df, X_df, S_df = M5.load("data")
sf.plot(Y_df)
```

![](images/m5.png)

## mlforecast

```python
import lightgbm as lgbm
from mlforecast import MLForecast
from mlforecast.lag_transforms import ExpandingMean, RollingMean
from mlforecast.target_transforms import Differences

fcst = MLForecast(
    models=[lgbm.LGBMRegressor()],
    freq='D',
    lags=[7, 14],
    lag_transforms={
        1: [ExpandingMean()],
        7: [RollingMean(window_size=28)]
    },
    date_features=['dayofweek'],
    target_transforms=[Differences([1])],
)
```


## probabilistic forecats

todo

## hierarchical forecast

```python
from datasetsforecast.hierarchical import HierarchicalData
from hierarchicalforecast.core import HierarchicalReconciliation
from hierarchicalforecast.methods import BottomUp, TopDown, MiddleOut

# Create timeseries for all levels of the hierarchy
Y_df, S, tags = HierarchicalData.load('./data', 'TourismSmall')
# ...
Y_train_df, Y_test_df = ...

# Compute base predictions
fcst = StatsForecast(models=[AutoARIMA(season_length=4), freq='QE')
Y_hat_df = fcst.forecast(df=Y_train_df, h=4)

# Reconcile the base predictions
reconcilers = [
    BottomUp(),
    TopDown(method='forecast_proportions'),
    MiddleOut(middle_level='Country/Purpose/State',
              top_down_method='forecast_proportions')
]
hrec = HierarchicalReconciliation(reconcilers=reconcilers)
Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_train_df, S=S, tags=tags)
```

## neural forecast

todo

## foundational models

```python
from nixtla import NixtlaClient

nixtla_client = NixtlaClient(api_key = nixtla_api_key)
df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/electricity-short.csv')
fcst_df = nixtla_client.forecast(df, h=24, level=[80, 90])
nixtla_client.plot(df, fcst_df, level=[80, 90])
```

![](images/timegpt.png)

## refs

todo